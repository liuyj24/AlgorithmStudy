### 哈希函数和哈希表
##### 哈希函数
1. 哈希函数的输入域是无穷大的, 但输出域是有限的. 比如说java中的String.hashCode输出的就是一个有范围的字符串. 
2. 相同的输入会得到相同的输出, 一定不是随机的. 
3. 由于输入域无穷大而输出域有限, 肯定会碰到多个输入对应同一个输出的情况, 称之为"哈希碰撞"
4. **重点** 当输入的样本量很大的时候, 输出集合中的点每个点命中的次数是均匀增长的  
一个离散函数越好, 第4点性质体现越明显. 离散函数会充分打乱输入样本的规律, 输出样本和输入样本之间没有什么联系. 
---
> 引入一个哈希函数应用的具体例子 : 有一个大文件, 里面装有大小不超过64字节的url, 想知道大文件中哪个url出现的次数最多. 

1. 单机版(单内存)情况下, 最原始会想使用一个哈希表, 记录词频, 遍历得到最大值. 
2. 但是如果文件无限大, 一台机器的内存不够用, 必须要多台机器协作. (文件系统本来也是分布式文件系统).
3. 假如100台机器勉强撑得起这个应用. 对应开头哈希函数的知识, 通过哈希函数计算每个url的哈希值, 就是一个从无穷输入域到有限输出域的过程, 然后我们对得到的哈希值模上100(假设哈希值都是整数), 那么就得到0~99的值, 这也是一个从大输入到有限输出的过程. 
4. 我们假设大文件中通过hash函数计算出的哈希值有A种, 那么每台机器上就分得 A/100 种, 我们在每台机器上再进行词频统计, 最后把100个最大值再求一次最大值就可以得到最终的结果. 

> 反过来总结一下:为什么要用这么多机器, 也就是为什么内存会不够用. 担心的是通过hash函数计算出来的哈希值种类太多. 如果种类少的话用hash表是完全可以装的下的, 就是怕种类多, 内存不够用, 所以分到不同的机器上.   

> 也不用担心每台机器算出来的值会一样, 理解了整个过程就不会有这样的疑问, 因为哈希值已经是不一样的了, 只是通过求余再次分配, 肯定也是不一样的. 

---
##### 哈希表
1. HashMap和HashSet底层的结构差不多, 但是HashMap中的key多了一个value作为附带值, HashSet没有这个value值. 下面以HashMap进行分析. 
2. 假设有一个长度为17的数组(经典hash表就是17, 反正是质数), 经过`%17`的哈希函数计算出哈希值存放到数组中, 如果冲突了就用链表链起来. 

> 这时候会有一个问题, 如果我有17亿的数据, 那么每个链表上就是1亿个元素, 还能说操作的时间复杂度为O(1)吗? 下面引入工程中哈希表的扩容问题. 

3. 当有一个哈希值上的链表长度等于7(根据散列性, 其他可能也差不多到7了), 我们认为hash表的性能开始下降, 进行扩容. 
4. 扩容一次数组长度增加为37(比2倍大, 且最近的质数). 这时候我们要把原来的数据重新通过新的哈希函数`%37`计算后放到哈希表中, 时间复杂度是O(n). 但是由于我们的扩容不是经常发生, 承受不了才进行扩容, 假设最终的数据规模为n, 我们扩容次数为Logn, 并不是很多. 但是工程中有办法把它降为O(1).   
比如说离线扩容的做法, 用户使用的hash表需要扩容时, 创建另外一条线程对老哈希表进行扩容得出一个新的哈希表, 并搬运好数据. 在扩容的过程中, 用户还是使用老的哈希表, 直到新的哈希表建好后, 用户就会使用新的哈希表, 老哈希表被销毁. 在这过程中, 用户的体验不会降低. 感觉还是O(1)那么快速. 
5. 上面讲的是经典的哈希表, 在实际中, 以java的HashMap为例, 假设数组长度为17, 它的桶如果发生冲突后连接的都不是链表, 而是一棵红黑树, 红黑树是一棵有序树, 红黑树增删改查的时间复杂度是O(logn).   
红黑树结构在java中是TreeMap, c++中是orderdMap